{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseOutputMessage(id='msg_092ce1c48829761d0068f18c4c321481a2a6e668b347a6e04b', content=[ResponseOutputText(annotations=[], text='As the moonlight danced on the shimmering lake, the gentle unicorn whispered secrets to the stars, promising sweet dreams to every child who believed in magic.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"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\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\",\n",
    "    temperature=0.6,\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fbc4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time: 2025-10-18T16:50:40.506847\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "print(f\"Current date and time: {current_datetime.isoformat()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d6c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthony/.local/share/uv/python/cpython-3.13.3-macos-x86_64-none/lib/python3.13/pty.py:95: DeprecationWarning: This process (pid=65810) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies:                                  \u001b[0m\n",
      "\u001b[31m  ╰─▶ \u001b[0mBecause only the following versions of torch are available:\n",
      "\u001b[31m      \u001b[0m    torch==1.0.0\n",
      "\u001b[31m      \u001b[0m    torch==1.0.1\n",
      "\u001b[31m      \u001b[0m    torch==1.1.0\n",
      "\u001b[31m      \u001b[0m    torch==1.2.0\n",
      "\u001b[31m      \u001b[0m    torch==1.3.0\n",
      "\u001b[31m      \u001b[0m    torch==1.3.1\n",
      "\u001b[31m      \u001b[0m    torch==1.4.0\n",
      "\u001b[31m      \u001b[0m    torch==1.5.0\n",
      "\u001b[31m      \u001b[0m    torch==1.5.1\n",
      "\u001b[31m      \u001b[0m    torch==1.6.0\n",
      "\u001b[31m      \u001b[0m    torch==1.7.0\n",
      "\u001b[31m      \u001b[0m    torch==1.7.1\n",
      "\u001b[31m      \u001b[0m    torch==1.8.0\n",
      "\u001b[31m      \u001b[0m    torch==1.8.1\n",
      "\u001b[31m      \u001b[0m    torch==1.9.0\n",
      "\u001b[31m      \u001b[0m    torch==1.9.1\n",
      "\u001b[31m      \u001b[0m    torch==1.10.0\n",
      "\u001b[31m      \u001b[0m    torch==1.10.1\n",
      "\u001b[31m      \u001b[0m    torch==1.10.2\n",
      "\u001b[31m      \u001b[0m    torch==1.11.0\n",
      "\u001b[31m      \u001b[0m    torch==1.12.0\n",
      "\u001b[31m      \u001b[0m    torch==1.12.1\n",
      "\u001b[31m      \u001b[0m    torch==1.13.0\n",
      "\u001b[31m      \u001b[0m    torch==1.13.1\n",
      "\u001b[31m      \u001b[0m    torch==2.0.0\n",
      "\u001b[31m      \u001b[0m    torch==2.0.1\n",
      "\u001b[31m      \u001b[0m    torch==2.1.0\n",
      "\u001b[31m      \u001b[0m    torch==2.1.1\n",
      "\u001b[31m      \u001b[0m    torch==2.1.2\n",
      "\u001b[31m      \u001b[0m    torch==2.2.0\n",
      "\u001b[31m      \u001b[0m    torch==2.2.1\n",
      "\u001b[31m      \u001b[0m    torch==2.2.2\n",
      "\u001b[31m      \u001b[0m    torch==2.3.0\n",
      "\u001b[31m      \u001b[0m    torch==2.3.1\n",
      "\u001b[31m      \u001b[0m    torch==2.4.0\n",
      "\u001b[31m      \u001b[0m    torch==2.4.1\n",
      "\u001b[31m      \u001b[0m    torch==2.5.0\n",
      "\u001b[31m      \u001b[0m    torch==2.5.1\n",
      "\u001b[31m      \u001b[0m    torch==2.6.0\n",
      "\u001b[31m      \u001b[0m    torch==2.7.0\n",
      "\u001b[31m      \u001b[0m    torch==2.7.1\n",
      "\u001b[31m      \u001b[0m    torch==2.8.0\n",
      "\u001b[31m      \u001b[0m    torch==2.9.0\n",
      "\u001b[31m      \u001b[0mand torch<=2.4.1 has no wheels with a matching Python ABI tag (e.g.,\n",
      "\u001b[31m      \u001b[0m`\u001b[36mcp313\u001b[39m`), we can conclude that torch<=2.4.1 cannot be used.\n",
      "\u001b[31m      \u001b[0mAnd because torch>=2.5.0 has no wheels with a matching platform tag\n",
      "\u001b[31m      \u001b[0m(e.g., `\u001b[36mmacosx_15_0_x86_64\u001b[39m`) and you require torch, we can conclude that\n",
      "\u001b[31m      \u001b[0myour requirements are unsatisfiable.\n",
      "\n",
      "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.13\u001b[39m (`\u001b[36mcp313\u001b[39m`), but we only found wheels for\n",
      "\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv2.4.1\u001b[39m) with the following Python ABI tags: `\u001b[36mcp38\u001b[39m`, `\u001b[36mcp39\u001b[39m`,\n",
      "\u001b[31m      \u001b[0m`\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`, `\u001b[36mcp312\u001b[39m`\n",
      "\n",
      "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m Wheels are available for `\u001b[36mtorch\u001b[39m` (\u001b[36mv2.9.0\u001b[39m) on the following\n",
      "\u001b[31m      \u001b[0mplatforms: `\u001b[36mmanylinux_2_28_aarch64\u001b[39m`, `\u001b[36mmanylinux_2_28_x86_64\u001b[39m`,\n",
      "\u001b[31m      \u001b[0m`\u001b[36mmacosx_11_0_arm64\u001b[39m`, `\u001b[36mwin_amd64\u001b[39m`\n"
     ]
    }
   ],
   "source": [
    "!uv pip install torch torchvision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter-project",
   "language": "python",
   "name": "my-jupyter-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
